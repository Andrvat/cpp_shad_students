{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопросы для повторения:**\n",
    "* что такое `std::mutex`? зачем он нужен? что внутри?\n",
    "* что такое `std::lock_guard`? чем не устраивают `std::mutex::lock`, `std::mutex::unlock`?\n",
    "* предположим, у нас есть многопоточная очередь задач `MTTasksQueue`. В чём здесь проблема? Как её будем исправлять?\n",
    "\n",
    "```c++\n",
    "void run_queued_task(MTTasksQueue& q)\n",
    "{\n",
    "    if (!q.empty())\n",
    "        run_task(q.pop());\n",
    "}\n",
    "```\n",
    "\n",
    "* а в чём может быть проблема с той же самой очередью тут? Какие есть варианты её исправить?\n",
    "\n",
    "```c++\n",
    "class MTTasksQueue\n",
    "{\n",
    "public:\n",
    "    using Task = std::function<void(void)>;\n",
    "    \n",
    "    ...\n",
    "\n",
    "    void pop_and_run()\n",
    "    {\n",
    "        std::lock_guard guard(mtx);\n",
    "\n",
    "        if (!tasks_queue.empty())\n",
    "        {        \n",
    "            const auto task = std::move(tasks_queue.back());\n",
    "            tasks_queue.pop_back();\n",
    "            task();\n",
    "        }        \n",
    "    }\n",
    "\n",
    "private:\n",
    "    std::mutex mtx;\n",
    "    std::queue<Task> tasks_queue;\n",
    "};\n",
    "```\n",
    "\n",
    "<details>\n",
    "<summary>ответ</summary>\n",
    "<p>recursive_mutex и реорганизация кода. Что такое и как устроен recursive_mutex? Когда его следует использовать? Почему в данном случае recursive_mutex - плохое решение? Если остаться на обычном mutex, как следует с ним поступить?</p>\n",
    "</details>\n",
    "\n",
    "* Что такое deadlock? Каким минимальным числом потоков и mutex-ов устроить deadlock?\n",
    "\n",
    "<details>\n",
    "<summary>замечание</summary>\n",
    "<p>\"на самом деле\", дважды вызов lock у std::mutex на одном потоке - это не обязательно deadlock. Документация утверждает, что это UB, и _скорее всего_ вы получите deadlock, но некоторые реализации могут задетектить ситуацию и бросить exception, но в общем случае всё совсем плохо - это UB</p>\n",
    "<p><a href=\"https://en.cppreference.com/w/cpp/thread/mutex/lock\">proof</a></p>\n",
    "</details>\n",
    "\n",
    "\n",
    "* что такое и зачем нужны `shared_mutex`, `unique_lock`, `shared_lock` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Многопоточность. Продвинутый материал."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Документация:\n",
    "* https://en.cppreference.com/w/cpp/atomic\n",
    "* https://en.cppreference.com/w/cpp/atomic/memory_order\n",
    "\n",
    "Серия статей от Jeff Pershing на понимание atomics, memory model && lock free:\n",
    "* https://preshing.com/20120515/memory-reordering-caught-in-the-act/\n",
    "* https://preshing.com/20120612/an-introduction-to-lock-free-programming\n",
    "* https://preshing.com/20120625/memory-ordering-at-compile-time/\n",
    "* https://preshing.com/20120710/memory-barriers-are-like-source-control-operations/\n",
    "* https://preshing.com/20120913/acquire-and-release-semantics/\n",
    "* https://preshing.com/20120930/weak-vs-strong-memory-models/\n",
    "* https://preshing.com/20121019/this-is-why-they-call-it-a-weakly-ordered-cpu/\n",
    "* https://preshing.com/20130618/atomic-vs-non-atomic-operations/\n",
    "* https://preshing.com/20130702/the-happens-before-relation/\n",
    "* https://preshing.com/20130922/acquire-and-release-fences/\n",
    "* https://preshing.com/20130823/the-synchronizes-with-relation/\n",
    "* https://preshing.com/20130930/double-checked-locking-is-fixed-in-cpp11/\n",
    "* https://preshing.com/20131125/acquire-and-release-fences-dont-work-the-way-youd-expect/\n",
    "* https://preshing.com/20140709/the-purpose-of-memory_order_consume-in-cpp11/\n",
    "* В конце своих статей Джефф даёт ссылки на полезные материалы, их тоже рекомендуется почитать. Не стоит рассчитывать, что управитесь со всем багажом знаний за полчасика.\n",
    "* И в комментарии к статьям приходят специалисты (Herb Sutter, Tarvis Downs), и объясняют, в чём Джефф был не прав, поэтому комментарии желательно тоже смотреть.\n",
    "\n",
    "Другие статьи:\n",
    "* [Memory Barriers: a Hardware View for Software Hackers](http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.07.23a.pdf)\n",
    "* [LINUX KERNEL MEMORY BARRIERS](https://www.kernel.org/doc/Documentation/memory-barriers.txt)\n",
    "* [Максим Хижинский. Lock-free Data Structures. Basics: Atomicity and Atomic Primitives](https://kukuruku.co/post/lock-free-data-structures-basics-atomicity-and-atomic-primitives/)\n",
    "* [Bjarne Stroustrup про ABA-проблему и как её решать](http://www.stroustrup.com/isorc2010.pdf)\n",
    "\n",
    "Доклады про многопоточность:\n",
    "* [CppCon 2017: Fedor Pikus “C++ atomics, from basic to advanced. What do they really do?”](https://www.youtube.com/watch?v=ZQFzMfHIxng)\n",
    "* [CppCon 2018: Bryce Adelstein Lelbach “The C++ Execution Model”](https://www.youtube.com/watch?v=FJIn1YhPJJc)\n",
    "* [CppCon 2019: Bryce Adelstein Lelbach “The C++20 Synchronization Library”](https://www.youtube.com/watch?v=Zcqwb3CWqs4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### thread-based vs task-based модели организации вычислений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первой лекции про многопоточность мы неявно затронули это разделение.\n",
    "\n",
    "Повторим материал, вспомним задачу параллельного поиска максимума в массиве."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для простоты демонстрации вынесем функцию, которая считает максимум на части массива:\n",
    "    \n",
    "```c++\n",
    "int max_by_block(const std::vector<int>& arr, const unsigned block_ix, const unsigned blocks_count)\n",
    "{\n",
    "    const unsigned block_size = arr.size() / blocks_count;\n",
    "    \n",
    "    // для простоты демонстрации, чтобы не обрабатывать хвосты и ошибки\n",
    "    assert(block_size);\n",
    "    assert(block_size * blocks_count == arr.size());\n",
    "    assert(block_ix < blocks_count);\n",
    "\n",
    "    const unsigned start_ix = block_size * block_ix;\n",
    "    return *max_element(begin(arr) + start_ix,\n",
    "                        begin(arr) + start_ix + block_size);\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решение через потоки:\n",
    "\n",
    "```c++\n",
    "int parallel_max(const std::vector<int>& arr, const unsigned threads_count)\n",
    "{\n",
    "    // maximum per threads\n",
    "    std::vector<int> results(threads_count, 0);\n",
    "\n",
    "    // create threads to search for maximum\n",
    "    std::vector<std::thread> threads;\n",
    "    for (unsigned i = 0; i < threads_count; ++i)\n",
    "        threads.emplace_back([i, threads_count, &results](){\n",
    "            results[i] = max_by_block(arr, i, threads_count);\n",
    "        });\n",
    "\n",
    "    // wait for threads to complete\n",
    "    for (auto& t : threads)\n",
    "        t.join();\n",
    "\n",
    "    return *max_element(begin(results), end(results));\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решение через async:\n",
    "\n",
    "```c++\n",
    "int parallel_max(const std::vector<int>& arr, const unsigned tasks_count)\n",
    "{\n",
    "    // создать |tasks_count| фоновых задач\n",
    "    std::vector<std::future<int>> futures;\n",
    "    for (unsigned i = 0; i < tasks_count; ++i)\n",
    "        futures.emplace_back(std::async(std::launch::async,\n",
    "                                        [&arr, =]() { return max_by_block(arr, i, tasks_count); }));\n",
    "\n",
    "    // collect results and reduce\n",
    "    int res = INT_MIN;\n",
    "    for (auto& f: futures)\n",
    "        res = std::max(res, f.get());\n",
    "\n",
    "    return res;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы можете отметить, что визуально разница не так уж и велика, но нужно отметить следующее:\n",
    "    \n",
    "* в решении через потоки:\n",
    "    * строго зафиксировано число потоков, на котором запускаются вычисления\n",
    "    * строго задан момент создания потоков и момент их уничтожения\n",
    "    * пользователь выражает свои намерения в терминах _\"создать поток, запустить вычисления, уничтожить поток\"_\n",
    "    \n",
    "\n",
    "* в решении через `async` (через задачи) от пользователя скрывается информация \n",
    "    * от пользователя через интерфейс async спрятана (почти) информация сколько создаётся потоков, когда они создаются, продолжают ли они жить после выполнения задачи\n",
    "    * пользователь выражает свои намерения в терминах _\"выполнить фоновую задачу\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### executors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Развитие task-based моделей организации служат Executors - классы / мезанизмы управления фоновыми задачами.\n",
    "\n",
    "Пока что в С++ executors не стандартизированы, только в процессе, поэтому каждый пишет во что горазд. В целом executor может позволять делать следующее:\n",
    "* запуск фоновой задачи\n",
    "* отмена фоновой задачи\n",
    "* поддержка приоритетов задач\n",
    "* поддержка зависимостей между задачами\n",
    "* управление внутренним пулом потоков:\n",
    "    * фиксированное число потоков / плавающее число потоков\n",
    "    * момент создания и уничтожения потоков\n",
    "* управление внутренней очередью задач"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ориентировочный вариант интерфейса executor (понятно, тут у каждого свои вариации):\n",
    "    \n",
    "```c++\n",
    "class Executor\n",
    "{\n",
    "public:\n",
    "    // кол-во потоков для выполнения задач задаём в конструкторе,\n",
    "    // пусть он сам принимает решение, когда система перегружена,\n",
    "    // и требуется отсыпать ещё потоков, либо наоборот, задачи\n",
    "    // кончились и потоки можно уничтожить, высвободить память\n",
    "    Executor(const unsigned min_threads_count,\n",
    "             const unsigned max_threads_count);\n",
    "    \n",
    "    // запланировать выполнение задачи\n",
    "    // (вариант, принятый +- в chromium)\n",
    "    //\n",
    "    // Callable - может быть std::function или\n",
    "    // std::packaged_task или любой другой класс,\n",
    "    // умеющий представлять собой некоторую задачу\n",
    "    //\n",
    "    // TaskParams - набор параметров задачи, могут,\n",
    "    // например, содержать приоритет, отладочную\n",
    "    // инфомрацию и другие параметры, отвечающие на\n",
    "    // вопрос \"как выполнить эту задачу\"\n",
    "    //\n",
    "    // Callback - куда отсылать результат задачи\n",
    "    template<typename Callable, typename Callback>\n",
    "    bool post_task(Callable&& task, TaskParams params, Callback&& callback);\n",
    "    \n",
    "    // вариант реализации через std::future\n",
    "    // (+- более в стиле std::async)\n",
    "    template<typename Result, typename Callable>\n",
    "    std::future<Result> post_task(Callable&& task, TaskParams params);\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно, как вариант, создать экземпляр класса `Executor` как глобальную переменную. И надо аккуратно проработать потокобезопасность такого решения (либо однопоточный доступ до объекта либо потокобезопасная реализация)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда пользоваться подходом через потоки, когда - через задачи - зависит от... задачи.\n",
    "\n",
    "\n",
    "**Пример**, когда решение через потоки может быть лучше:\n",
    "\n",
    "Параллельный поиск оптимума в горячем месте программы\n",
    "  * нужно строго контроллировать количество потоков\n",
    "  * нужно строго контроллировать время их жизни\n",
    "  * нужна синхронизация меджу потоками\n",
    "\n",
    "\n",
    "**Пример**, когда решение через задачи может быть лучше:\n",
    "\n",
    "Мы пишем браузер.\n",
    "\n",
    "* <i>задача 1</i>: пользователь открыл сайт, нужно распарсить ответ от сервера, затем распарсить html-ку и отдать её на рендеринг.\n",
    "\n",
    "  Нельзя парсить в главном потоке программы, иначе UI подвиснет и не будут реагировать кнопки меню. Нужно парсить в фоне.\n",
    "  \n",
    "  Скорость выполнения этой задачи важна для пользователя, её влияние на UX приложения критично.\n",
    "  \n",
    "  <i>Решение</i>: запостить фоновую задачу парсинга ответа и html-ки с высоким приоритетом.\n",
    "  \n",
    "  <i>Псевдокод:</i>\n",
    "  \n",
    "```c++\n",
    "void process_server_response(const Response& response)\n",
    "{\n",
    "    global_executor.post_task(bind(parse_server_response, response),\n",
    "                              TaskParams{ HIGH_PRIORITY },\n",
    "                              process_raw_html);\n",
    "}\n",
    "\n",
    "void process_raw_html(const std::string& html)\n",
    "{\n",
    "    global_executor.post_task(bind(parse_html, html),\n",
    "                              TaskParams{ HIGH_PROPRITY },\n",
    "                              render_html);\n",
    "}\n",
    "\n",
    "void render_html(const HTML& html)\n",
    "{\n",
    "    // rendering code ...\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "* <i>задача 2</i>: пользователь запускает установку расширения в браузере.\n",
    "\n",
    "  Установка сторонних расширений - процесс длительный. Не критично, если расширение не установится моментально, но и час установку ждать никто не будет.\n",
    "\n",
    "  <i>Решение</i>: запостить фоновую задачу по установке расширения со средним приоритетом.\n",
    "  \n",
    "  \n",
    "* <i>задача 3</i>: Браузер периодически запускает очистку данных на диске (протухшие кеши страниц / изображений, удалённые оставшиеся на диске расширения, прочистка БД от мусора)\n",
    "\n",
    "  Цель - освободить место на диске, которое занято мусором, и слегка ускорить работу, уменьшив объём данных.\n",
    "  \n",
    "  Пользователю всё равно сколько будет идти задача, он даже не знает о её существовании.\n",
    "  \n",
    "  <i>Решение</i>: запостить фоновую задачу очистки с самым низким приоритетом. Если потоки executor-а будут забиты высокоприоритетными задачами, и наша не стартует, никто не заметит проблемы, очистка отработает на следующий запуск браузера или через час/день/месяц."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Замечание**: Task-based орагнизация - более высокий уровень абстракции чем thread-based. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Замечание**: В домашнем задании про тайловую карту С++ вам нужно будет сделать именно task-based решение с фиксированным числом фоновых потоков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### atomic basics (since C++11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним задачу параллельного суммирования массива из второй лекции на многопоточность.\n",
    "\n",
    "Её реализация с ошибкой:\n",
    "\n",
    "```c++\n",
    "int parallel_sum(const std::vector<int>& v, const unsigned threads_count)\n",
    "{\n",
    "    const unsigned len = v.size() / threads_count;\n",
    "    assert(len * threads_count == v.size());\n",
    "\n",
    "    int rv = 0;\n",
    "\n",
    "    std::vector<std::thread> threads;\n",
    "    for (unsigned i = 0; i < threads_count; ++i)\n",
    "        threads.emplace_back([&v, &rv, i, len](){\n",
    "            for (unsigned ix = len * i, final_ix = len * (i + 1); ix < final_ix; ++ix)\n",
    "                 rv += v[ix];\n",
    "        });\n",
    "\n",
    "    for (auto& t: threads)\n",
    "        t.join();\n",
    "\n",
    "    return rv;\n",
    "}\n",
    "```\n",
    "\n",
    "**Вопрос**: напомните, в чём ошибка?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во второй лекции проблему решали через `mutex`.\n",
    "\n",
    "**Вопрос**: как лучше всего решить задачу, чтобы синхронизаций было поменьше?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас будем писать тоже неидеальное решение - через `std::atomic`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Атомарность операции означает, что никакой из потоков не может отследить промежуточное состояние операции: либо состояние до изменений, либо состояние после изменений.\n",
    "\n",
    "**Пример:**\n",
    "\n",
    "`std::atomic<int>` имеет операцию `fetch_add`:\n",
    "\n",
    "`var.fetch_add(int x)` имеет три условных стадии выполнения:\n",
    "\n",
    "1. считать текущее значение из памяти в регистр\n",
    "2. увеличить регистр на значение `x`\n",
    "3. записать значение регистра в память\n",
    "\n",
    "Никакой поток не может вклиниться в работу с `var`, пока выполняются шаги 1-2-3. Он либо работает с `var` до шага 1, либо после шага 3.\n",
    "\n",
    "\n",
    "**Вопрос:** в примере ниже:\n",
    "1. какое значение `counter` возможно после того как потоки выполняют свою работу?\n",
    "2. если бы гарантии атомарности не было, какое значение мы могнли бы получить?\n",
    "\n",
    "```c++\n",
    "std::atomic<int> counter{0};\n",
    "\n",
    "void thread_1_worker() { counter.fetch_add(1); }\n",
    "void thread_2_worker() { counter.fetch_add(1); }\n",
    "\n",
    "std::thread t1(thread_1_worker), t2(thread_2_worker);\n",
    "t1.join(); t2.join();\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из документации по типу `atomic<T>`:\n",
    "\n",
    "> Each instantiation and full specialization of the `std::atomic` template defines an atomic type. If one thread writes to an atomic object while another thread reads from it, the behavior is well-defined (see memory model for details on data races)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие типы `T` можно подставлять?\n",
    "\n",
    "Обратимся опять к документации:\n",
    "\n",
    "> The primary `std::atomic` template may be instantiated with any `TriviallyCopyable` type `T` satisfying both `CopyConstructible` and `CopyAssignable`. The program is ill-formed if any of following values is false:\n",
    "* `std::is_trivially_copyable<T>::value`\n",
    "* `std::is_copy_constructible<T>::value`\n",
    "* `std::is_move_constructible<T>::value`\n",
    "* `std::is_copy_assignable<T>::value`\n",
    "* `std::is_move_assignable<T>::value`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.е. для любого `TriviallyCopyable` типа `T` объект типа `std::atomic<T>` потокобезопасен на чтение и запись.\n",
    "\n",
    "```c++\n",
    "struct Point\n",
    "{\n",
    "    float x;\n",
    "    float y;\n",
    "    float z;\n",
    "};\n",
    "\n",
    "std::atomic<Point> p;\n",
    "\n",
    "void thread_1_worker() {\n",
    "    p = Point{1.f, 2.f, 3.f};  // ok\n",
    "}\n",
    "\n",
    "void thread_2_worker() {\n",
    "    Point x = p;  // ok\n",
    "}\n",
    "```\n",
    "\n",
    "А вот эти примеры - ill-formed:\n",
    "\n",
    "```c++\n",
    "std::atomic<std::string> s;  // ill-formed\n",
    "std::atomic<std::vector<int>> v;  // ill-formed\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### atomic vs mutex: performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каких-то сложных типов (например, `Point`) `std::atomic` реализуется через `std::mutex` или аналогичным образом.\n",
    "\n",
    "Если бы так было для всех типов, то особого смысла в `std::atomic` бы не было.\n",
    "\n",
    "Смысл в том, что для простых типов (`int`, `bool`, `int64_t` ...) многие CPU поддерживают более дешёвые способы синхронизации. Набор типов и степень их дешевизны зависят от архитектуры CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем реализацию паралелльной суммы через `std::atomic<int>`:\n",
    "\n",
    "```c++\n",
    "int parallel_sum(const std::vector<int>& v, const unsigned threads_count)\n",
    "{\n",
    "    const unsigned len = v.size() / threads_count;\n",
    "    assert(len * threads_count == v.size());\n",
    "\n",
    "    std::atomic<int> rv{0};\n",
    "\n",
    "    std::vector<std::thread> threads;\n",
    "    for (unsigned i = 0; i < threads_count; ++i)\n",
    "        threads.emplace_back([&v, &rv, i, len](){\n",
    "            for (unsigned ix = len * i, final_ix = len * (i + 1); ix < final_ix; ++ix)\n",
    "                 rv.fetch_add(v[ix]);\n",
    "        });\n",
    "\n",
    "    for (auto& t: threads)\n",
    "        t.join();\n",
    "\n",
    "    return rv;\n",
    "}\n",
    "```\n",
    "\n",
    "И через `std::mutex`:\n",
    "\n",
    "```c++\n",
    "int parallel_sum(const std::vector<int>& v, const unsigned threads_count)\n",
    "{\n",
    "    const unsigned len = v.size() / threads_count;\n",
    "    assert(len * threads_count == v.size());\n",
    "\n",
    "    int rv = 0;\n",
    "    std::mutex m;\n",
    "\n",
    "    std::vector<std::thread> threads;\n",
    "    for (unsigned i = 0; i < threads_count; ++i)\n",
    "        threads.emplace_back([&v, &rv, &m, i, len](){\n",
    "            for (unsigned ix = len * i, final_ix = len * (i + 1); ix < final_ix; ++ix)\n",
    "            {\n",
    "                std::lock_guard guard(m);\n",
    "                rv += v[ix];                \n",
    "            }\n",
    "        });\n",
    "\n",
    "    for (auto& t: threads)\n",
    "        t.join();\n",
    "\n",
    "    return rv;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И сравним производительность на 6 потоках (тестовая машинка: 6 физических ядер Intel Core i5-8400):\n",
    "\n",
    "```sh\n",
    "g++ parallel_sum_atomic.cpp -lpthread -O3 -std=c++17 -o sum_atomic.exe && ./sum_atomic.exe\n",
    "g++ parallel_sum_mutex.cpp  -lpthread -O3 -std=c++17 -o sum_mutex.exe  && ./sum_mutex.exe\n",
    "```\n",
    "\n",
    "вывод:\n",
    "\n",
    "```sh\n",
    "parallel sum atomic:\n",
    "  size          = 60000000\n",
    "  threads_count = 6\n",
    "  result        = 60000000\n",
    "  time, sec     = 1.60537\n",
    " \n",
    "parallel sum mutex:\n",
    "  size          = 60000000\n",
    "  threads_count = 6\n",
    "  result        = 60000000\n",
    "  time, sec     = 6.33526\n",
    "```\n",
    "\n",
    "В зависимости от примитива синхронизации получилось добиться 4-х кратного ускорения алгоритма, что существенно.\n",
    "Такой эффект достигается за счёт того, что в алгоритме слишком агрессивно используется синхронизация данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы оценить что происходит в бинарном коде закинем файл на godbolt.org (gcc 9.2 -O3 -std=c++17):\n",
    "\n",
    "```c++\n",
    "#include <atomic>\n",
    "#include <mutex>\n",
    "\n",
    "int mutexed_counter = 0;\n",
    "std::mutex m;\n",
    "\n",
    "std::atomic<int> atomic_counter{0};\n",
    "\n",
    "void add_mutexed(int value)\n",
    "{\n",
    "    std::lock_guard guard{m};\n",
    "    mutexed_counter += value;\n",
    "}\n",
    "\n",
    "void add_atomic(int value)\n",
    "{\n",
    "    atomic_counter += value;\n",
    "}\n",
    "```\n",
    "\n",
    "**Вопрос**: Перед тем как посмотреть на ответ, подскажите, что происходит внутри `lock_guard` и `mutex` в этом коде?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```asm\n",
    "add_mutexed(int):\n",
    "        push    rbp\n",
    "        mov     ebp, OFFSET FLAT:_ZL28__gthrw___pthread_key_createPjPFvPvE\n",
    "        push    rbx\n",
    "        mov     ebx, edi\n",
    "        sub     rsp, 8\n",
    "        test    rbp, rbp\n",
    "        je      .L2\n",
    "        mov     edi, OFFSET FLAT:m\n",
    "        call    __gthrw_pthread_mutex_lock(pthread_mutex_t*)\n",
    "        test    eax, eax\n",
    "        jne     .L12\n",
    ".L2:\n",
    "        add     DWORD PTR mutexed_counter[rip], ebx\n",
    "        test    rbp, rbp\n",
    "        je      .L1\n",
    "        add     rsp, 8\n",
    "        mov     edi, OFFSET FLAT:m\n",
    "        pop     rbx\n",
    "        pop     rbp\n",
    "        jmp     __gthrw_pthread_mutex_unlock(pthread_mutex_t*)\n",
    ".L1:\n",
    "        add     rsp, 8\n",
    "        pop     rbx\n",
    "        pop     rbp\n",
    "        ret\n",
    ".L12:\n",
    "        mov     edi, eax\n",
    "        call    std::__throw_system_error(int)\n",
    "        \n",
    "add_atomic(int):\n",
    "        lock add        DWORD PTR atomic_counter[rip], edi\n",
    "        ret\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутри `add_mutexed` можно наблюдать уход в ядро ОС через `pthread`.\n",
    "\n",
    "А весь `add_atomic` - одна инструкция `lock add` - особая атомарная инструкция сложения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### atomics: hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала рассмотрим hardware-нюансы обзорно.\n",
    "\n",
    "Вспомним многоуровневую организацию кешей памяти:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cpu_caches_ram.png\" width=50% height=50% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При работе многопоточного приложения одна и та же ячейка памяти может оказаться одновременно в разных кешах L1 разных CPU.\n",
    "\n",
    "Если при этом происходит только чтение из памяти, то проблем не возникает. Возникают проблемы, когда нужна запись.\n",
    "\n",
    "Записанное значение должно \"просочиться\" по всем уровням иерархии кешей вплоть до RAM... и обновиться в кешах соседних CPU.\n",
    "\n",
    "Процесс \"просачивания\" не быстрый, другие CPU могут читать устаревшее значение или попытаться записать своё.\n",
    "\n",
    "Особые atomic-инструкции решают эту проблему, они гарантируют, что записанное одним CPU значение \"просочится\" по всей иерархии кешей и будет корректно прочитано другими CPU.\n",
    "\n",
    "Поэтому атомарные инструкции (как правило - зависит от железа) медленнее аналогичных неатомарных инструкций:\n",
    "  * `+=` для `std::atomic<int>` будет медленнее чем для `int`\n",
    "  * также работа с `std::atomic<int>` отключает некоторые оптимизации компилятора (подробности в разделе про instruction reordering && memory model)\n",
    "\n",
    "Это упрощённое описание. Пока что его будет достаточно для дальнейшей работы. Большие нюансы о гарантиях и оптимизации atomic - раздел про memory model, о нём позже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### instructions reordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://preshing.com/20120625/memory-ordering-at-compile-time/\n",
    "* https://preshing.com/20120710/memory-barriers-are-like-source-control-operations/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переупорядочивание инструкций - изменение порядка выполняемых команд \"без видимых эффектов\" - одна из оптимизаций программ, будучи полностью прозрачной для однопоточного кода, начинает играть роль для некорректного многопоточного кода (для корректного всё хорошо).\n",
    "\n",
    "Важно, что _ассемблерные_ инструкции не могут быть переупорядочены, если между ними есть зависимость по данным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переупорядочивание инструкций можно разделить на 2 типа:\n",
    "* в compile time\n",
    "* в runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**compile-time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во-первых, компилятор может решить, что лучше команды выполнять не в той последовательности, в которой их описал программист.\n",
    "\n",
    "Рассмотрим такой код:\n",
    "\n",
    "```c++\n",
    "\n",
    "double some_value = 0.;\n",
    "bool value_is_set = false;\n",
    "\n",
    "\n",
    "void run_setup()\n",
    "{\n",
    "    some_value = 3.14;    // между some_value и value_is_set нет зависимости\n",
    "    value_is_set = true;  // по данным, компилятор вправе поменять присванивания местами\n",
    "}\n",
    "\n",
    "void process()\n",
    "{\n",
    "    if (value_is_set)\n",
    "        assert(some_value == 3.14);\n",
    "}\n",
    "```\n",
    "\n",
    "В однопоточном приложении здесь всё будет хорошо, а в многопоточном и так плохо т.к. нет нужных синхронизаций, но переупорядочивание инструкций может увеличить вероятность ошибки.\n",
    "\n",
    "\n",
    "Другой пример с переупорядочиванием инструкций, когда зависимость по данным есть в плюсовом коде, но её нет на увроне инструкций ассемблера:\n",
    "\n",
    "```c++\n",
    "int A, B;\n",
    "\n",
    "void foo()\n",
    "{\n",
    "    A = B + 1;\n",
    "    B = 0;\n",
    "}\n",
    "```\n",
    "\n",
    "Здесь компилятор так же вправе сгенерировать запись в ячейку памяти B раньше чем в A:\n",
    "\n",
    "либо так:\n",
    "\n",
    "```asm\n",
    "mov     eax, DWORD PTR _B  (redo this at home...)\n",
    "add     eax, 1\n",
    "mov     DWORD PTR _A, eax\n",
    "mov     DWORD PTR _B, 0\n",
    "```\n",
    "\n",
    "либо так:\n",
    "\n",
    "```asm\n",
    "mov     eax, DWORD PTR B\n",
    "mov     DWORD PTR B, 0\n",
    "add     eax, 1\n",
    "mov     DWORD PTR A, eax\n",
    "```\n",
    "\n",
    "Опять же, для однопоточного кода такие трюки должны быть прозрачны. Они начинают играть свою роль только для многопоточного кода.\n",
    "\n",
    "**Замечание**: есть способ запретить копилятору переупорядочивать некоторые операции, добавив барьер, [подробнее - читайте по ссылке выше](https://preshing.com/20120625/memory-ordering-at-compile-time/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**runtime**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во-вторых, даже если компилятор сохранил последовательность команд программиста, CPU может иметь своё мнение, и решить, что быстрее будет их выполнить в ином порядке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим пример такого устройства:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](cpu_mem_organization.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой схеме у каждого ядра \"своя личная область работы\" - кеш L1, а \"общая область\" - кеш L2 + RAM.\n",
    "\n",
    "Рассмотрим случай, когда в какой-то программе поток 1 выполняет код на ядре 1, а поток 2 выполняет код на ядре 2:\n",
    "\n",
    "```c++\n",
    "int x = 0, y = 0, z = 0;\n",
    "int a = 0, b = 0, c = 0;\n",
    "\n",
    "void thread_1_worker_on_cpu_1() {\n",
    "    x = 1; y = 2; z = 3;\n",
    "    \n",
    "    if (b == 5)\n",
    "        assert(a == 4);  // fail\n",
    "}\n",
    "\n",
    "void thread_2_worker_on_cpu_2() {\n",
    "    a = 4; b = 5; c = 6;\n",
    "\n",
    "    if (y == 2)\n",
    "        assert(x == 1);  // fail\n",
    "}\n",
    "```\n",
    "\n",
    "В таком коде нет гарантий на порядок записи / чтения между \"личной областью работы\" и \"общей областью работы\".\n",
    "\n",
    "* Порядок, кто из `x`, `y`, `z` раньше попадёт в L2 + RAM не определён, так же как и время, через которое они туда попадут.\n",
    "  * вполне может оказаться так, что z улетит в RAM первым, а x и y ещё долго провисят недоставленными по адресу в L1\n",
    "* Аналогично, не определён порядок попадания `a`, `b`, `c` в \"общую область работы\"\n",
    "* Хуже того, не определён порядок попадания `x`, `y`, `z` в \"личную область работы\" потока 2, т.е. при чтении тоже нет гарантий, что поток 2, увидев `y == 2`, получит `x == 1`\n",
    "* Ещё хуже, если запустить поток 3 на cpu 3, он может увидеть совсем другую последовательность значений `x`, `y`, `z`, чем поток 2\n",
    "\n",
    "При таких условиях многопоточных код писать невозможно. Чтобы справляться с этими проблемами есть особые барьеры памяти (их много и разных видов), о них поговорим чуть позже.\n",
    "\n",
    "Если коротко, без использования барьеров памяти:\n",
    "* значения на запись уходят в \"общую область\" сколь угодно долго и в произвольном порядке\n",
    "* значения на чтение приходят в \"личную область\" сколько угодно долго и в произвольном порядке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### double checked locking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://preshing.com/20130930/double-checked-locking-is-fixed-in-cpp11/\n",
    "\n",
    "http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html\n",
    "\n",
    "https://www.aristeia.com/Papers/DDJ_Jul_Aug_2004_revised.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DCLP - double checked locking pattern - популярный шаблон организации потокобезопасного доступа к данным/объектам с ленивой инициализацией. Пример: синглтоны с ленивой инициализацией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос-напоминалка**: что такое синглтон?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однопоточный вариант организации ленивого синглтона:\n",
    "    \n",
    "```c++\n",
    "class Singleton\n",
    "{\n",
    "    static Singleton* object;\n",
    "\n",
    "public:\n",
    "    static Singleton* instance()\n",
    "    {\n",
    "        if (!object)\n",
    "            object = new Singleton;\n",
    "        return object;\n",
    "    }\n",
    "};\n",
    "```\n",
    "\n",
    "**Вопрос**: Почему эта реализация не работает в многопоточной среде? Приведите пример последовательности выполнения потоков, при котором возникает ошибка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Многопоточный вариант реализации ленивого синглтона:\n",
    "    \n",
    "```c++\n",
    "class Singleton\n",
    "{\n",
    "    static Singleton* object;\n",
    "    static std::mutex mtx;\n",
    "\n",
    "public:\n",
    "    static Singleton* instance()\n",
    "    {\n",
    "        std::lock_guard guard(mtx);\n",
    "        \n",
    "        if (!object)\n",
    "            object = new Singleton;\n",
    "        return object;\n",
    "    }\n",
    "};\n",
    "```\n",
    "\n",
    "**Вопрос**: корректна ли эта реализация? Какие у неё проблемы?\n",
    "\n",
    "<details>\n",
    "<summary>ответ</summary>\n",
    "<p>\n",
    "\n",
    "Корректна, но очень дорого: когда синглтон инициализирован каждый из потоков спотыкается об `mutex` при доступе к синглтону. `mutex`-ы уходят в kernel space, хочется что-нибудь подешевле.\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант double checked locking pattern:\n",
    "\n",
    "```c++\n",
    "class Singleton\n",
    "{\n",
    "    static Singleton* object;\n",
    "    static std::mutex mtx;\n",
    "\n",
    "public:\n",
    "    static Singleton* instance()\n",
    "    {\n",
    "        if (!object)  // check 1\n",
    "        {\n",
    "            std::lock_guard guard(mtx);\n",
    "\n",
    "            if (!object)  // check 2\n",
    "                object = new Singleton;\n",
    "        }\n",
    "        return object;\n",
    "    }\n",
    "};\n",
    "```\n",
    "\n",
    "**Вопросы**: (чтобы тщательно разобрать код)\n",
    "* зачем нужна вторая проверка, будет ли код корректен без неё?\n",
    "* корректен ли код?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Со временем в этом шаблоне нашли хитрые race condition, что отчасти и подтолкнуло сообщество к формализации memory model в языках Java и С++.\n",
    "* до Java 2004 DCLP не работал [(подробности)](http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html)\n",
    "* до С++11 не было портируемого способа реализовать DCLP (стандарт не давал необходимых для этого инструментов и гарантий) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема в этой строчке:\n",
    "    \n",
    "```c++\n",
    "object = new Singleton;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Программист мог бы подумать, что этот код выполняется в такой последовательности:\n",
    "* выделить память под `Singleton`\n",
    "* позвать конструктор `Singleton`\n",
    "* записать указатель в `object`\n",
    "\n",
    "Здесь в игру вступает instructions reordering.\n",
    "\n",
    "Например, если компилятор может доказать, что конструктор `Singleton` не бросает исключений, он вправе сгенерировать такой код:\n",
    "\n",
    "```c++\n",
    "class Singleton\n",
    "{\n",
    "    static Singleton* object;\n",
    "    static std::mutex mtx;\n",
    "\n",
    "public:\n",
    "    static Singleton* instance()\n",
    "    {\n",
    "        if (!object)  // check 1\n",
    "        {\n",
    "            std::lock_guard guard(mtx);\n",
    "\n",
    "            if (!object)  // check 2\n",
    "            {\n",
    "                object = operator new(sizeof(Singleton));\n",
    "                new (object) Singleton;\n",
    "            }\n",
    "        }\n",
    "        return object;\n",
    "    }\n",
    "};\n",
    "```\n",
    "\n",
    "**Вопрос:** в чём здесь проблема? как её можно поймать?\n",
    "\n",
    "Как это пытались починить различными способами до стандартизации модели памяти, и почему они не работают - [в статье от Мейерса и Александреску](https://www.aristeia.com/Papers/DDJ_Jul_Aug_2004_revised.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Корректная реализация double checked locking pattern будет выглядеть так:\n",
    "\n",
    "```c++\n",
    "class Singleton\n",
    "{\n",
    "    static std::atomic<Singleton*> object;\n",
    "    static std::mutex mtx;\n",
    "\n",
    "public:\n",
    "    static Singleton* instance()\n",
    "    {\n",
    "        auto* tmp = object.load();\n",
    "\n",
    "        if (!tmp)  // check 1\n",
    "        {\n",
    "            std::lock_guard<std::mutex> lock(mtx);\n",
    "\n",
    "            tmp = object.load();\n",
    "            if (!tmp)  // check 2\n",
    "            {\n",
    "                tmp = new Singleton;\n",
    "                object.store(tmp);\n",
    "            }\n",
    "        }\n",
    "        return tmp;\n",
    "    }\n",
    "};\n",
    "```\n",
    "\n",
    "В этом примере методы `load`/`store` у атомарных типов гарантируют корректный порядок операций между потоками.\n",
    "\n",
    "Как именно получаются гарантии и как сделать реализацию быстрее - рассмотрим позже, когда поговорим про memory model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы хотим ленивую инициализацию синглтона, то 11-ый стандарт даёт два варианта, которые скрывают проблемы DCLP от программиста:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вариант 1**: специальная конструкция для ленивых многопоточных синглтонов - `static`-переменные внутри функции:\n",
    "\n",
    "```c++\n",
    "class Singleton\n",
    "{\n",
    "public:\n",
    "    static Singleton& instance()\n",
    "    {\n",
    "        static Singleton object;\n",
    "        return object;\n",
    "    }\n",
    "};\n",
    "```\n",
    "\n",
    "`static`-переменные внутри функций/методов (не путать с глобальными `static`-переменными!):\n",
    "* инициализируются лениво при первом обращении\n",
    "* компилятор с поддержкой С++11 обязан сгенерировать потокобезопасную инициализацию переменной. Компилятор не знает, будет этот код использован в многопоточном варианте или в однопоточном, поэтому он всегда генерирует безопасный многопоточный вариант\n",
    "* компилятор не обязан использовать DCLP, он может выбрать любой способ, который на его взгляд, работает лучше для данного случая, поэтому:\n",
    "\n",
    "```c++\n",
    "#include <string>\n",
    "\n",
    "float get_circle_area(const float radius)\n",
    "{\n",
    "    // скорее всего, здесь не будет никаких синхронизаций,\n",
    "    // но и static в этом месте - лишнее, лучше удалить\n",
    "    static const float pi = 3.14f;\n",
    "    return pi * radius * radius;\n",
    "}\n",
    "\n",
    "std::string add_12345(const std::string& x)\n",
    "{\n",
    "    // скорее всего, здесь будет синхронизация\n",
    "    static const std::string s = \"12345\";\n",
    "    return x + s;\n",
    "}\n",
    "```\n",
    "\n",
    "Закинуть на godbolt.org этот пример, показать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос на понимание**: в чём разница этих двух решений?\n",
    "\n",
    "```c++\n",
    "std::string add_12345_1(const std::string& x)\n",
    "{\n",
    "    static const std::string s = \"12345\";\n",
    "    return x + s;\n",
    "}\n",
    "```\n",
    "\n",
    "и\n",
    "\n",
    "```c++\n",
    "static const std::string s = \"12345\";\n",
    "\n",
    "std::string add_12345_2(const std::string& x)\n",
    "{\n",
    "    return x + s;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вариант 2**: `std::call_once` (since C++11)\n",
    "\n",
    "https://en.cppreference.com/w/cpp/thread/call_once\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c++\n",
    "template< class Callable, class... Args >\n",
    "void call_once( std::once_flag& flag, Callable&& f, Args&&... args );\n",
    "```\n",
    "\n",
    "> Executes the Callable object `f` exactly once, even if called concurrently, from several threads.\n",
    "\n",
    "`std::call_once` позволяет гарантировать, что какая-то работа будет выполнена только один раз в многопоточной среде."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более подробно про использование:\n",
    "\n",
    "```c++\n",
    "// какая-то работа, единоразовое выполнение которой нужно гарантировать\n",
    "void some_job(int param) {  /*...*/ }\n",
    "\n",
    "// где-то завели флажок, была ли выполнена работа\n",
    "// (специальный тип std::once_flag)\n",
    "std::once_flag my_flag;\n",
    "\n",
    "// вызываем std::call_once в любом потоке:\n",
    "std::vector<std::thread> threads;\n",
    "for (int i = 0; i != 5; ++i)\n",
    "    threads.emplace_back([&once_flag, i](){\n",
    "        /* .. */\n",
    "        \n",
    "        std::call_once(once_flag, some_job, i);\n",
    "        \n",
    "        /* ... */        \n",
    "    });\n",
    "\n",
    "for (auto& t : threads)\n",
    "    t.join();\n",
    "```\n",
    "\n",
    "В этом примере гарантировано, что `some_job` *отработает* только единожды (с каким `param` - неизвестно, с которым первым получится). Когда `some_job` *отработает*, флаг `my_flag` будет взведён, и больше `some_job` не будет вызываться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос**: какие в С++ есть (адекватные) стратегии обработки ошибок?\n",
    "\n",
    "<details>\n",
    "<summary>ответ</summary>\n",
    "\n",
    "код возврата и исключения\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`std::call_once` немножко хитрее, он умеет понимать, произошла ли ошибка в `some_job`. Если в `some_job` произошла ошибка, то он не считает, что работа выполнена.\n",
    "\n",
    "Ошибку `std::call_once` определяет по тому, вылетело ли из `some_job` исключение или выполнение функции завершилось стандартным способом.\n",
    "* Если выполнение завершается стандартным способом - флаг взводится, считается, что работа выполнена\n",
    "* Если вылетает исключение:\n",
    "  * флаг НЕ взводится\n",
    "  * исключение пролетает сквозь `std::call_once` наружу тому, кто `std::call_once` позвал \n",
    "  * следующий вызов `std::call_once` снова попытается выполнить работу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разберём пример:\n",
    "\n",
    "```c++\n",
    "#include <atomic>\n",
    "#include <exception>\n",
    "#include <iostream>\n",
    "#include <mutex>\n",
    "#include <sstream>\n",
    "#include <string>\n",
    "#include <thread>\n",
    "#include <vector>\n",
    "\n",
    "std::atomic_int attempts_count{0};\n",
    "\n",
    "std::string s;\n",
    "\n",
    "void print_thread_msg(const std::string& message)\n",
    "{\n",
    "    std::stringstream ss;\n",
    "    ss << \"thread \" << std::this_thread::get_id() << ' ' << message << '\\n';\n",
    "    std::cout << ss.str();\n",
    "}\n",
    "\n",
    "void construct_object()\n",
    "{\n",
    "    const int before_add = attempts_count.fetch_add(1);\n",
    "    if (before_add < 5)\n",
    "    {\n",
    "        print_thread_msg(\"gets an attempt ix = \" + std::to_string(before_add) + \" and throws an exception\");\n",
    "        throw std::runtime_error(\"try again\");\n",
    "    }\n",
    "\n",
    "    print_thread_msg(\"gets an attempt ix = \" + std::to_string(before_add) + \" and constructs the value\");\n",
    "\n",
    "    s = \"hello c++\";\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    std::once_flag once_init_flag;\n",
    "\n",
    "    std::vector<std::thread> threads;\n",
    "    for (int i = 0; i != 10; ++i)\n",
    "        threads.emplace_back([&](){\n",
    "            try\n",
    "            {\n",
    "                std::call_once(once_init_flag, construct_object);\n",
    "            }\n",
    "            catch (const std::exception&) {}\n",
    "        });\n",
    "\n",
    "    for (auto& thr: threads)\n",
    "        thr.join();\n",
    "\n",
    "    std::cout << \"value is: \" << s << std::endl;\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопросы**:\n",
    "* сколько потоков создаётся?\n",
    "* сколько войдёт в `construct_object`?\n",
    "* какой ожидается вывод?\n",
    "* зачем отдельно вынесен такой страшный `print_thread_msg`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скомпилируем пример clang-ом с clang-овской стандартной библиотекой libc++ и запустим:\n",
    "    \n",
    "```sh\n",
    "clang++-8 -O2 call_once.cpp -lpthread -stdlib=libc++\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод:\n",
    "\n",
    "```sh\n",
    "thread 139683658577664 gets an attempt ix = 0 and throws an exception\n",
    "thread 139683641792256 gets an attempt ix = 1 and throws an exception\n",
    "thread 139683650184960 gets an attempt ix = 2 and throws an exception\n",
    "thread 139683535251200 gets an attempt ix = 3 and throws an exception\n",
    "thread 139683510073088 gets an attempt ix = 4 and throws an exception\n",
    "thread 139683526858496 gets an attempt ix = 5 and constructs the value\n",
    "value is: hello c++\n",
    "```\n",
    "\n",
    "Обратите внимание, что после того как функция `construct_object`, переданная в `std::call_once`, завершила свою работу без пробрасывания исключений, больше никто `construct_object` не вызывает - работает гарантия `std::call_once`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь скомпилируем тот же самый код gcc со стандартной билиотекой libstdc++ и запустим:\n",
    "\n",
    "```sh\n",
    "g++ -O2 call_once.cpp -lpthread\n",
    "```\n",
    "\n",
    "И он... зависнет:\n",
    "\n",
    "```sh\n",
    "thread 139670308796160 gets an attempt ix = 0 and throws an exception\n",
    "# зависание тут\n",
    "```\n",
    "\n",
    "**Вопрос**: попробуйте догадаться, где ошибка?\n",
    "\n",
    "<details>\n",
    "<summary>ответ</summary>\n",
    "    \n",
    "В нашем коде ошибки нет, это [баг библиотеки libstdc++](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=66146), известный ещё с 2015 года. В комбинации libstdc++ + posix threads не поддержана работа с исключениями в `std::call_once`. Можно для интереса зайти [на документацию `std::call_once`](https://en.cppreference.com/w/cpp/thread/call_once) и попробовать прогнать пример из документации.\n",
    "\n",
    "Мораль - даже если вы написали идеальный код по стандарту, не забудьте его протестировать перед тем как <s>показать студентам</s> выпустить в production.\n",
    "\n",
    "Тесты - хоть какая-то уверенность.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Резюме** по блоку double checked locking pattern:\n",
    "* instructions reordering может принести неожиданные сюрпризы в многопоточных программах\n",
    "* гарантии на последовательность операций дают `std::atomic`-операции со стандарта С++11\n",
    "* если нужно лениво инициализировать глобальную переменную / константу, предпочтительнее использовать `static`-переменную внутри функции / метода, хороший компилятор выберет наиболее предпочтительный способ синхронизации для вашего случая.\n",
    "* если нужно гарантировать разовое выполнение работы в многопоточной среде - используйте связку `std::call_once + std::once_flag`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение производительности `static` / `call_once` и других подходов:\n",
    "    \n",
    "http://www.modernescpp.com/index.php/thread-safe-initialization-of-a-singleton\n",
    "    \n",
    "Спойлер: `static` всех победил"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### spinlock && гибриды"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос**: как устроен внутри `std::mutex`, что происходит при вызовах методов `lock`/`unlock`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В некоторых случаях использование `std::mutex` может оказаться слишком дорогим.\n",
    "\n",
    "Рассмотрим случай, когда защищаемый участок кода выполняется очень быстро:\n",
    "\n",
    "```c++\n",
    "std::vector<int> v;\n",
    "std::mutex mtx;\n",
    "\n",
    "void add_item(int item)\n",
    "{\n",
    "    std::lock_guard guard(mtx);\n",
    "    v.push_back(item);\n",
    "}\n",
    "```\n",
    "\n",
    "Зачастую `v.push_back` отрабатывает очень быстро, всего несколько инструкций: увеличить размер на 1 элемент и записать целое в область памяти. Время его работы значительно меньше, чем двойной уход в kernel space для `std::mutex` при вызовах `lock`/`unlock`. В такой функции всё время работы уходит на синхронизацию.\n",
    "\n",
    "Хочется подешевле.\n",
    "\n",
    "**Вопрос**: какой вариант после знакомства с сегодняшней лекцией вы могли бы предложить для таких блокировок?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`spinlock` - вариант решения проблемы на атомарных операциях.\n",
    "\n",
    "Простейшая его реализация:\n",
    "* атомарный флаг занятости\n",
    "* в `lock` подождать, пока флаг не станет \"свободным\", выставить \"занято\"\n",
    "* в `unlock` выставить \"свободно\"\n",
    "\n",
    "Вариант реализации (если понимать memory model, можно реализовать быстрее):\n",
    "\n",
    "https://en.cppreference.com/w/cpp/atomic/atomic_flag\n",
    "\n",
    "```c++\n",
    "class spin_lock\n",
    "{\n",
    "    std::atomic_flag busy = ATOMIC_FLAG_INIT;\n",
    "    \n",
    "public:\n",
    "    void lock()\n",
    "    {\n",
    "        // test_and_set - устанавливает флаг в true и\n",
    "        // возвращает предыдущее значение\n",
    "        //\n",
    "        // (если вернуло false, значит, это мы изменили\n",
    "        //  флаг false -> true)\n",
    "        \n",
    "        while (busy.test_and_set())  // acquire lock\n",
    "             ; // spin\n",
    "    }\n",
    "    \n",
    "    void unlock()\n",
    "    {\n",
    "        busy.clear();  // release lock\n",
    "    }\n",
    "};\n",
    "\n",
    "// Вопрос: почему это работает? как два потока будут бороться за lock?\n",
    "```\n",
    "\n",
    "И потом можно сделать так:\n",
    "\n",
    "```c++\n",
    "std::vector<int> v;\n",
    "SpinLock spin_lock;\n",
    "\n",
    "void add_item(int item)\n",
    "{\n",
    "    std::lock_guard guard(spin_lock);\n",
    "    v.push_back(item);\n",
    "}\n",
    "```\n",
    "\n",
    "и `add_item` начнёт работать значительно быстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос**: Если бы spinlock был так хорош, то можно было бы просто все `std::mutex` позаменять на spinlock и не мучиться. В чём проблема spinlock, чем он хуже `mutex`?\n",
    "\n",
    "<details>\n",
    "<summary>ответ</summary>\n",
    "<p>\n",
    "\n",
    "* `std::mutex` усыпляет висящий на его `lock`-е поток средствами ОС. Пока поток висит на `std::mutex`, ОС закинет на физическое ядро другие потоки, выполняющие полезную работу\n",
    "* `spinlock` оккупирует ядро в `lock` в цикле `while`, никому не отдавая свой фрейм выполнения. Если `spinlock` висит долго, он впустую крутит физическое ядро вместо того чтобы отдать ресурсы на полезную работу.\n",
    "\n",
    "</p>    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Поэтому для простых решений выработано правило:**\n",
    "* если блокируемый участок кода выполняется быстро - `spinlock`\n",
    "* если блокируемый участок кода выполняется медленно - `std::mutex`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть варианты частичного исправления проблемы `spinlock`-а - `spinlock` с засыпанием. Идея реализации метода `lock`:\n",
    "* покрутиться недолго на атомике в ожидании значения \"свободно\"\n",
    "* усыпить поток на время `x` (через `std::this_thread::yield`, например)\n",
    "* покрутиться недолго на атомике в ожидании значения \"свободно\"\n",
    "* усыпить поток на время `2 * x`\n",
    "* покрутиться недолго на атомике в ожидании значения \"свободно\"\n",
    "* усыпить поток на время `4 * x`\n",
    "* покрутиться недолго на атомике в ожидании значения \"свободно\"\n",
    "* усыпить поток на время `8 * x`\n",
    "...\n",
    "\n",
    "т.е. после некоторой оккупации физического ядра и кручения его на спинлоке всё-таки принять решение отдать ядро кому-то другому, а самому уснуть. Время засыпания увеличивать в геометрической прогрессии до некоторой верхней границы.\n",
    "\n",
    "Тоже допустимое решение, но `std::mutex` и здесь может начать выигрывать на длительных ожиданиях:\n",
    "* во время `std::this_thread::yield` поток не знает, когда проснуться, он будет спать запрошенное время, а событие разблокировки, например, произойдёт в середине сна.\n",
    "* к тому же остаются расходы на оккупацию физического ядра, но они меньше\n",
    "* в случае с `std::mutex` ОС знает, когда нужно разбудить ожидающий поток"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае, когда объём вычислений под блокировкой предсказать сложно (или не хочется думать), иногда используют гибридный вариант блокировки:\n",
    "* сначала покрутиться несколько раз на `atomic_flag`\n",
    "* если через atomic разрулить не получилось, уйти через `std::mutex` в kernel space, и пусть ОС сама решает когда нас разбудить\n",
    "\n",
    "Так, например, сделан [Webkit WTF::Lock](https://webkit.org/blog/6161/locking-in-webkit/) (статья объёмная, но полезная, почитайте)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### intro to lock free programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://preshing.com/20120612/an-introduction-to-lock-free-programming\n",
    "    \n",
    "Jeff Pershing даёт следующее определение lock-free:\n",
    "\n",
    "> lock free programming = multithreaded app + shared memory + threads do not lock each other\n",
    "\n",
    "Под \"threads do not lock each other\" понимается, что при любом причудливом планировании распределения фреймов cpu по потокам работа будет продвигаться. Если даже ОС полностью усыпила какой-то один поток, остальные продолжат выполнять работу по алгоритму.\n",
    "\n",
    "**Вопрос**: если принять такое определение, почему любой алгоритм с использованием mutex не является lock free?\n",
    "\n",
    "**Замечание**: к такому определению следует относиться с некоторой долей скепсиса и понимания его неидеальности. Предположим, у нас есть lock-free очередь задач с одним потоком, создающим заадачи и несколькими потоками, их выполняющими (например, ваша домашняя работа с тайловой картой). Почему такая очередь не совсем lock-free?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример:** пример без мьютексов с атомарным `х` равным 0 на входе, который НЕ lock free:\n",
    "    \n",
    "```c++\n",
    "while (X == 0)\n",
    "    X = 1 - X;\n",
    "```\n",
    "\n",
    "**Вопрос:** каким образом два апотока могут здесь друг друга залочить\n",
    "\n",
    "**Следствие:** отсутствие `mutex`-ов и `spin_lock`-ов ещё не делает алгоритм lock free"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другое определение lock free:\n",
    "    \n",
    "> as long as the program is able to keep calling those lock-free operations, the number of completed calls keeps increasing, no matter what"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если по какой-то причине после сегодняшней лекции (её примеров и упрощений) вам покажется, что lock-free - простая тема, [здесь](https://preshing.com/20131125/acquire-and-release-fences-dont-work-the-way-youd-expect/) пример как Jeff Pershing находит ошибку в презентации про атомики и барьеры от Герба Саттера (генсека <s>КПСС</s> КСС++, второго человека в мире С++)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### hardware memory model (simplified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://preshing.com/20120930/weak-vs-strong-memory-models/\n",
    "\n",
    "memory ordering - правила упорядочивания операций с памятью можно разделить на:\n",
    "\n",
    "* правила языка для абстрактной машины\n",
    "    * и вы программу пишите с ними и только под них\n",
    " \n",
    "* hardware-специфичные правила\n",
    "    * применяются в зависимости от железа, на котором выполняется программа - под них программу писать не надо, но желательно понимать, чтобы понимать, каких ошибок можно ожидать от железа, когда в программе наошибались в правилах языка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поговорим про hardware memory ordering\n",
    "\n",
    "Варианты:\n",
    "* really weak\n",
    "* weak with data dependency\n",
    "* usually strong\n",
    "* sequentially consistent\n",
    "\n",
    "![](weak-strong-table-4.png)\n",
    "\n",
    "**really weak**\n",
    "\n",
    "(Без специальных барьеров) нет никаких гарантий:\n",
    "\n",
    "Вспомним пример:\n",
    "\n",
    "```c++\n",
    "int x = 0, y = 0, z = 0;\n",
    "int a = 0, b = 0, c = 0;\n",
    "\n",
    "void thread_1_worker_on_cpu_1() {\n",
    "    x = 1; y = 2; z = 3;\n",
    "\n",
    "    if (b == 5)\n",
    "        assert(a == 4);  // fail\n",
    "}\n",
    "\n",
    "void thread_2_worker_on_cpu_2() {\n",
    "    a = 4; b = 5; c = 6;\n",
    "\n",
    "    if (y == 2)\n",
    "        assert(x == 1);  // fail\n",
    "}\n",
    "```\n",
    "\n",
    "Нет никаких гарантий на порядок/время записи данных в \"общую память (L2 + RAM)\", ровно как и на порядок/время их просачивания до \"частной памяти ЦПУ (L1)\".\n",
    "\n",
    "\n",
    "**weak with data dependency**\n",
    "\n",
    "Появляется гарантия (из статьи Джеффа):\n",
    "\n",
    "> It means that if you write A->B in C/C++, you are always guaranteed to load a value of B which is at least as new as the value of A\n",
    "\n",
    "на примере:\n",
    "\n",
    "```c++\n",
    "int x = 0, y = 0;\n",
    "int a = 0, b = 0;\n",
    "\n",
    "void thread_1_worker_on_cpu_1() {\n",
    "    x = 1;\n",
    "    y = x;  // <---- в одну ячейку памяти пишем содержимое другой\n",
    "    \n",
    "    a = 1;\n",
    "    b = 1;  // больше x, y, a, b никто не трогает\n",
    "}\n",
    "\n",
    "void thread_2_worker_on_cpu_2() {\n",
    "    if (y == 1)\n",
    "        assert(x == 1);  // ok\n",
    "\n",
    "    if (b == 1)\n",
    "        assert(a == 1);  // fail\n",
    "}\n",
    "```\n",
    "\n",
    "**Замечание:** У меня есть сомнения про это утверждение Джеффа, т.к. вроде бы ничто не мешает компилятору соптимизировать до `y = 1` ещё до того как hardware memory model вступает в игру.\n",
    "\n",
    "**strong model**\n",
    "\n",
    "> A strong hardware memory model is one in which every machine instruction comes implicitly with acquire and release semantics. As a result, when one CPU core performs a sequence of writes, every other CPU core sees those values change in the same order that they were written.\n",
    "\n",
    "**Замечание**: Несмотря на то, что к strong model бодро отнесён x86/64, не все операции в x86/64 поддерживают strong memory model, читайте исходную статью и комментарии.\n",
    "\n",
    "**Замечание**: ниже написан код плюсовый, но сделаем вид, будто компилятор ничего переупорядочивать не будет, если будет - всё неверно. Мы как будто бы пишем на ассемблере в синтаксисе плюсов.\n",
    "\n",
    "```c++\n",
    "int x = 0, y = 0, z = 0;\n",
    "\n",
    "void thread_1_worker_on_cpu_1() {\n",
    "    x = 1;\n",
    "    y = 2;\n",
    "    z = 3;\n",
    "}\n",
    "\n",
    "void thread_2_worker_on_cpu_2() {\n",
    "    if (z == 3) {\n",
    "        assert(y == 2);  // ok\n",
    "        assert(x == 1);  // ok\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "В strong модели разрешено переупорядочивание операций store-load (запись-чтение) (но запрещены load-store, store-store && load-load)\n",
    "\n",
    "```c++\n",
    "int x = 0, y = 0;\n",
    "int a = 0, b = 0;\n",
    "\n",
    "void thread_1_worker_on_cpu_1() {\n",
    "    x = 1;  // store x\n",
    "    a = y;  // load y\n",
    "            // store a\n",
    "}\n",
    "\n",
    "void thread_2_worker_on_cpu_2() {\n",
    "    y = 1;  // store y\n",
    "    b = x;  // load x\n",
    "            // store b\n",
    "}\n",
    "```\n",
    "\n",
    "В результате такого \"ассемблера\" может получиться `a = 0 && b = 0`.\n",
    "\n",
    "**Вопрос**: как?\n",
    "\n",
    "<details>\n",
    "<summary>ответ</summary>\n",
    "\n",
    "* cpu1: register1 = read y ( == 0)\n",
    "* cpu2: register2 = read x ( == 0)\n",
    "* cpu1: x = 1\n",
    "* cpu2: y = 1\n",
    "* cpu1: a = register1 ( == 0)\n",
    "* cpu2: b = register2 ( == 0)\n",
    "    \n",
    "    \n",
    "</details>\n",
    "\n",
    "\n",
    "**sequential consistent**\n",
    "\n",
    "Любое переупорядочивание запрещено, из примера выше `a = 0 && b = 0` не получить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C++ memory model (simplified, since C++11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.cppreference.com/w/cpp/atomic/memory_order\n",
    "\n",
    "https://preshing.com/20120913/acquire-and-release-semantics\n",
    "\n",
    "Теперь поговорим про memory ordering на уровне языка С++ - те, с которыми вам необходимо работать при написании программ.\n",
    "\n",
    "В стандартной библиотеке С++ определён enum для различного рода ограничений на переупорядочивание операций с памятью.\n",
    "\n",
    "```c++\n",
    "typedef enum memory_order {\n",
    "    memory_order_relaxed,\n",
    "    memory_order_consume,\n",
    "    memory_order_acquire,\n",
    "    memory_order_release,\n",
    "    memory_order_acq_rel,\n",
    "    memory_order_seq_cst\n",
    "} memory_order;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из них рассмотрим:\n",
    "\n",
    "```c++\n",
    "memory_order_relaxed\n",
    "memory_order_acquire\n",
    "memory_order_release\n",
    "memory_order_seq_cst\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`memory_order_release` означает, что все операции с памятью до `release`-барьера, не перейдут через барьер \"вперёд\".\n",
    "\n",
    "```c++\n",
    "x = 1;  // store x\n",
    "y = a;  // load a\n",
    "        // store y\n",
    "\n",
    "/*release barrier*/\n",
    "\n",
    "...  // операции, написанные выше с x, y и a\n",
    "     // не могут по времени произойти после release-барьера\n",
    "```\n",
    "\n",
    "`memory_order_acquire` означает, что все операции с памятью после `acquire`-барьера, не перейдёт через барьер \"назад\".\n",
    "\n",
    "```c++\n",
    "...  // операции, написанные ниже с x, y и a\n",
    "     // не могут по времени произойти раньше acquire-барьера\n",
    "\n",
    "/*acquire barrier*/\n",
    "\n",
    "x = 1;  // store x\n",
    "y = a;  // load a\n",
    "        // store y\n",
    "```\n",
    "\n",
    "**Пример:** разобрать очень подробно про гарантии порядка вычислений. Вопрос: почему assert корректен?\n",
    "\n",
    "```c++\n",
    "std::atomic<bool> is_published{false};\n",
    "int data = 0;\n",
    "\n",
    "void thread_1_worker()\n",
    "{\n",
    "    data = 1;\n",
    "    is_published.store(true, std::memory_order_release);\n",
    "}\n",
    "\n",
    "void thread_2_worker()\n",
    "{\n",
    "    if (is_published.load(std::memory_order_acquire))\n",
    "        assert(data == 1);  // ok\n",
    "}\n",
    "```\n",
    "\n",
    "Имена `release` и `acquire` подобраны по смыслу операции:\n",
    "* `release` - опубликовать данные\n",
    "* `acquire` - принять опубликованные данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`memory_order_seq_cst` - операции не могут перескочить через барьер ни в какую сторону (аналог sequential consistent hardware memory model) - самый строгий и самый медленный вариант\n",
    "\n",
    "`memory_order_seq_cst`:\n",
    "* дефолтный способ упорядочивания в `atomic`-операциях (чтобы программисты меньше ошибались)\n",
    "* аналог `volatile` в Java 5+\n",
    "\n",
    "\n",
    "\n",
    "```c++\n",
    "x = 1;  // store x\n",
    "y = a;  // load a\n",
    "        // store y\n",
    "\n",
    "/*seq_cst barrier*/  // никакая из операций не может перескочить через барьер\n",
    "\n",
    "z = 2;  // store x\n",
    "b = c;  // load c\n",
    "        // store b\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`memory_order_relaxed`:\n",
    "* возможны любые переупорядочивания операций с памятью (нет барьеров)\n",
    "* гарантируется только атомарная модификация защищённого объекта\n",
    "\n",
    "**Пример:**\n",
    "\n",
    "```c++\n",
    "std::atomic<int> atomic_var{0};\n",
    "\n",
    "// нет гарантий на порядок операций с памятью,\n",
    "// только атомарность работы с atomic_var\n",
    "void thread_worker() {\n",
    "    x = 1;\n",
    "    y = a;\n",
    "    atomic_var.store(2, std::memory_order_relaxed); \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разница в гарантиях порядка необходима из-за различной стоимости барьеров в CPU: чем строже гарантии, тем медленнее могут выполняться команды.\n",
    "\n",
    "* `relaxed` - самый быстрый (нет барьеров, только атомарность операции)\n",
    "* `acquire/release` - медленнее или аналогично `relaxed` (барьеры в одну сторону + атомарность операции)\n",
    "* `seq_cst` - медленнее или аналогично `acquire/release` (барьеры в обе стороны + атомарность операции)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### оптимизированный DCLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напомню DCLP, на котором мы закончили его рассмотрение:\n",
    "\n",
    "```c++\n",
    "class Singleton\n",
    "{\n",
    "    static std::atomic<Singleton*> object;\n",
    "    static std::mutex mtx;\n",
    "\n",
    "public:\n",
    "    static Singleton* instance()\n",
    "    {\n",
    "        auto* tmp = object.load();\n",
    "\n",
    "        if (!tmp)  // check 1\n",
    "        {\n",
    "            std::lock_guard<std::mutex> lock(mtx);\n",
    "\n",
    "            tmp = object.load();\n",
    "            if (!tmp)  // check 2\n",
    "            {\n",
    "                tmp = new Singleton;\n",
    "                object.store(tmp);\n",
    "            }\n",
    "        }\n",
    "        return tmp;\n",
    "    }\n",
    "};\n",
    "```\n",
    "\n",
    "**Вопрос:** как, зная про memory ordering, сделать более быструю реализацию?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:**\n",
    "\n",
    "```c++\n",
    "class Singleton\n",
    "{\n",
    "    static std::atomic<Singleton*> object;\n",
    "    static std::mutex mtx;\n",
    "\n",
    "public:\n",
    "    static Singleton* instance()\n",
    "    {\n",
    "        auto* tmp = object.load(std::memory_order_acquire);  // <--- mem order on read data\n",
    "\n",
    "        if (!tmp)  // check 1\n",
    "        {\n",
    "            std::lock_guard<std::mutex> lock(mtx);\n",
    "\n",
    "            tmp = object.load(std::memory_order_acquire);  // <--- mem order on read data\n",
    "            if (!tmp)  // check 2\n",
    "            {\n",
    "                tmp = new Singleton;\n",
    "                object.store(tmp, std::memory_order_release);  // <--- mem order on publish data\n",
    "            }\n",
    "        }\n",
    "        return tmp;\n",
    "    }\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### оптимизированная сумма элементов в массиве"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напомню как мы считали сумму элементов в массиве:\n",
    "    \n",
    "```c++\n",
    "int parallel_sum(const std::vector<int>& v, const unsigned threads_count)\n",
    "{\n",
    "    const unsigned len = v.size() / threads_count;\n",
    "    assert(len * threads_count == v.size());\n",
    "\n",
    "    std::atomic<int> rv{0};\n",
    "\n",
    "    std::vector<std::thread> threads;\n",
    "    for (unsigned i = 0; i < threads_count; ++i)\n",
    "        threads.emplace_back([&v, &rv, i, len](){\n",
    "            for (unsigned ix = len * i, final_ix = len * (i + 1); ix < final_ix; ++ix)\n",
    "                 rv.fetch_add(v[ix]);\n",
    "        });\n",
    "\n",
    "    for (auto& t: threads)\n",
    "        t.join();\n",
    "\n",
    "    return rv;\n",
    "}\n",
    "```\n",
    "\n",
    "**Вопрос:** как, зная про memory ordering, сделать более быструю реализацию?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:**\n",
    "\n",
    "```c++\n",
    "int parallel_sum(const std::vector<int>& v, const unsigned threads_count)\n",
    "{\n",
    "    const unsigned len = v.size() / threads_count;\n",
    "    assert(len * threads_count == v.size());\n",
    "\n",
    "    std::atomic<int> rv{0};\n",
    "\n",
    "    std::vector<std::thread> threads;\n",
    "    for (unsigned i = 0; i < threads_count; ++i)\n",
    "        threads.emplace_back([&v, &rv, i, len](){\n",
    "            for (unsigned ix = len * i, final_ix = len * (i + 1); ix < final_ix; ++ix)\n",
    "                 rv.fetch_add(v[ix], std::memory_order_relaxed);  // <---- no barriers, just atomic update\n",
    "        });\n",
    "\n",
    "    for (auto& t: threads)\n",
    "        t.join();\n",
    "\n",
    "    return rv;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### lock free stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На лекции мы реализуем lock free стэк с ошибками на базе списка и разберём ошибки.\n",
    "\n",
    "Как делать правильный - начните разбирать [с этой статьи](https://habr.com/ru/post/216013/) и далее по ссыкам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Шаг 1:** нарисовать стэк на доске и обсудить как сделать lock-free операции `push`/`pop`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Шаг 2:** накидаем примерную реализацию (объяснить каждую строчку)\n",
    "\n",
    "```c++\n",
    "template<typename T>\n",
    "class Stack {\n",
    "public:\n",
    "    struct Element\n",
    "    {\n",
    "        T data;\n",
    "        std::atomic<Element*> next;\n",
    "    };\n",
    "    \n",
    "private:\n",
    "    std::atomic<Element*> top;\n",
    "\n",
    "public:\n",
    "    bool push(value_type& val)\n",
    "    {\n",
    "        auto* t = top.load();\n",
    "        while (true)\n",
    "        {\n",
    "            val.next.store(t);\n",
    "            if (top.compare_exchange_strong(t, &val))       \n",
    "               return true;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    Element* pop()\n",
    "    {\n",
    "       while (true)\n",
    "       {\n",
    "          auto* t = top.load();\n",
    "          if (!t)\n",
    "             return nullptr ;  // stack is empty\n",
    "\n",
    "          auto* next = t->next.load();\n",
    "          if (top.compare_exchange_strong(t, next))\n",
    "          {\n",
    "              return /* somehow free memory for element t and return value */;\n",
    "          }\n",
    "       }\n",
    "    }\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Замечание:** если корректно заменить seq_cst операции на более слабые аналоги с relaxed && acquire/release порядком, то можно получить более быстрый код. Сейчас этим заниматься не будем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос:** где в коде ошибка?\n",
    "\n",
    "<details>\n",
    "<summary>ответ</summary>\n",
    "<p>\n",
    "\n",
    "тут:\n",
    "\n",
    "```c++\n",
    "auto* next = t->next.load();\n",
    "```\n",
    "\n",
    "как её поймать?\n",
    "\n",
    "Чтобы починить, нужно использовать специальные структуры данных, о них - по ссылке на правильную реализацию\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Замечание:** ещё в коде есть ABA-ошибка. (Объяснить её)\n",
    "\n",
    "Как чинить ABA-ошибки, [читайте в работе Страуструпа](http://www.stroustrup.com/isorc2010.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Резюме**:\n",
    "* вы не хотите писать lock-free алгоритмы в production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Неохваченные темы по параллельному программированию:**\n",
    "* процессы\n",
    "* fibers\n",
    "* futexes\n",
    "* semaphore\n",
    "* livelock\n",
    "* thread starving && fair algorithms\n",
    "* openmp введение\n",
    "* mpi введение"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
